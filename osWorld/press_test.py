import time
import concurrent.futures
from tqdm import tqdm
from openai import OpenAI
import statistics
import base64
import json

client = OpenAI(api_key="token-abc123", base_url="http://127.0.0.1:8000/v1")
model = client.models.list().data[0].id

def image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

msg = [
    {"role": "user", "content": [
        {"type": "text", "text": "ç»“åˆè¿™å¼ å›¾ï¼Œå†™ä¸€é¦–èµç¾jinchao10å’Œsunhao63ä¹‹é—´çˆ±æƒ…çš„è¯—æ­Œ"},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_to_base64('img.jpg')}"}}
    ]}
]
msg_json = json.dumps(msg)
msg_size_bytes = len(msg_json.encode('utf-8'))

print(f"æ¶ˆæ¯å¤§å°: {msg_size_bytes:,} bytes")
print(f"æ¶ˆæ¯å¤§å°: {msg_size_bytes / 1024:.1f} KB")
print(f"æ¶ˆæ¯å¤§å°: {msg_size_bytes / 1024 / 1024:.2f} MB")

for i in range(1000):
    start = time.time()
    resp = client.chat.completions.create(model=model, messages=msg, max_completion_tokens=1024)
    end = time.time()
    print(resp.choices[0].message.content)
    print(end - start)


# def make_request():
#     start = time.time()
#     try:
#         resp = client.chat.completions.create(
#             model=model, messages=msg, max_completion_tokens=64
#         )
#         end = time.time()
#         print(resp.choices[0].message.content)
#         print(end - start)
#         return True, end - start, resp.choices[0].message.content
#     except Exception as e:
#         end = time.time()
#         return False, end - start, str(e)

# def stress_test(concurrent_users, requests_per_user=10):
#     """å‹åŠ›æµ‹è¯•å‡½æ•°"""
#     total_requests = concurrent_users * requests_per_user
    
#     print(f"\nğŸš€ æµ‹è¯• {concurrent_users} ä¸ªå¹¶å‘ç”¨æˆ·ï¼Œæ¯ç”¨æˆ· {requests_per_user} è¯·æ±‚")
#     print(f"ğŸ“Š æ€»è¯·æ±‚æ•°: {total_requests}")
    
#     start_time = time.time()
    
#     # ä½¿ç”¨çº¿ç¨‹æ± æ¨¡æ‹Ÿå¹¶å‘ç”¨æˆ·
#     with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
#         # æ¯ä¸ªç”¨æˆ·å‘é€å¤šä¸ªè¯·æ±‚
#         futures = []
#         for user in range(concurrent_users):
#             for req in range(requests_per_user):
#                 futures.append(executor.submit(make_request))
        
#         # æ”¶é›†ç»“æœ
#         results = []
#         response_times = []
#         failed_count = 0
        
#         for future in tqdm(concurrent.futures.as_completed(futures), 
#                           total=total_requests, 
#                           desc=f"å¹¶å‘æ•°={concurrent_users}"):
#             success, response_time, content = future.result()
#             response_times.append(response_time)
            
#             if success:
#                 results.append(content)
#             else:
#                 failed_count += 1
    
#     end_time = time.time()
#     total_time = end_time - start_time
#     success_count = len(results)
#     success_rate = (success_count / total_requests) * 100
    
#     # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
#     avg_response_time = statistics.mean(response_times) if response_times else 0
#     p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) > 1 else 0
#     p99_response_time = statistics.quantiles(response_times, n=100)[98] if len(response_times) > 1 else 0
#     qps = success_count / total_time if total_time > 0 else 0
    
#     return {
#         'concurrent_users': concurrent_users,
#         'total_requests': total_requests,
#         'success_count': success_count,
#         'failed_count': failed_count,
#         'success_rate': success_rate,
#         'total_time': total_time,
#         'avg_response_time': avg_response_time,
#         'p95_response_time': p95_response_time,
#         'p99_response_time': p99_response_time,
#         'qps': qps
#     }

# # å‹åŠ›æµ‹è¯•é…ç½®
# test_configs = [1, 2, 5, 10, 20, 30, 50, 80, 100, 150, 200]  # å¹¶å‘ç”¨æˆ·æ•°
# requests_per_user = 5  # æ¯ä¸ªç”¨æˆ·å‘é€çš„è¯·æ±‚æ•°

# print("ğŸ”¥ å¼€å§‹å‹åŠ›æµ‹è¯• - å¯»æ‰¾æœåŠ¡æ€§èƒ½ä¸´ç•Œç‚¹")
# print("=" * 60)

# test_results = []

# for concurrent_users in test_configs:
#     result = stress_test(concurrent_users, requests_per_user)
#     test_results.append(result)
    
#     # å®æ—¶æ˜¾ç¤ºç»“æœ
#     print(f"""
# ğŸ“ˆ å¹¶å‘æ•°: {result['concurrent_users']:3d} | æˆåŠŸç‡: {result['success_rate']:5.1f}% | QPS: {result['qps']:6.1f}
#    å¹³å‡å“åº”: {result['avg_response_time']*1000:6.1f}ms | P95: {result['p95_response_time']*1000:6.1f}ms | P99: {result['p99_response_time']*1000:6.1f}ms
#    æˆåŠŸ/å¤±è´¥: {result['success_count']}/{result['failed_count']}
#     """)
    
#     # å¦‚æœæˆåŠŸç‡ä½äº80%ï¼Œå¯ä»¥æå‰åœæ­¢æµ‹è¯•
#     if result['success_rate'] < 80:
#         print("âš ï¸  æˆåŠŸç‡ä½äº80%ï¼Œå»ºè®®åœæ­¢æµ‹è¯•")
#         break
    
#     # çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…å¯¹æœåŠ¡é€ æˆæŒç»­å‹åŠ›
#     time.sleep(2)

# # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
# print("\n" + "=" * 60)
# print("ğŸ“Š å‹åŠ›æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
# print("=" * 60)

# print(f"{'å¹¶å‘æ•°':<8} {'æˆåŠŸç‡':<8} {'QPS':<10} {'å¹³å‡å“åº”(ms)':<12} {'P95(ms)':<10} {'P99(ms)':<10}")
# print("-" * 60)

# for result in test_results:
#     print(f"{result['concurrent_users']:<8} "
#           f"{result['success_rate']:<8.1f}% "
#           f"{result['qps']:<10.1f} "
#           f"{result['avg_response_time']*1000:<12.1f} "
#           f"{result['p95_response_time']*1000:<10.1f} "
#           f"{result['p99_response_time']*1000:<10.1f}")

# # æ‰¾åˆ°æœ€ä½³æ€§èƒ½ç‚¹
# best_qps = max(test_results, key=lambda x: x['qps'])
# stable_point = next((r for r in test_results if r['success_rate'] >= 95), None)

# print(f"\nğŸ† æœ€é«˜QPS: {best_qps['qps']:.1f} (å¹¶å‘æ•°: {best_qps['concurrent_users']})")
# if stable_point:
#     print(f"âœ… ç¨³å®šæœåŠ¡ç‚¹ (æˆåŠŸç‡â‰¥95%): å¹¶å‘æ•° {stable_point['concurrent_users']}, QPS {stable_point['qps']:.1f}")
# else:
#     print("âŒ æœªæ‰¾åˆ°ç¨³å®šæœåŠ¡ç‚¹ (æˆåŠŸç‡â‰¥95%)")